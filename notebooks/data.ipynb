{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd, numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/global/cfs/cdirs/m3443/usr/pmtuan/hadsim')\n",
    "import yaml\n",
    "from data.utils import *\n",
    "from data.datamodule import CartesianDataModule\n",
    "\n",
    "DATA_PATH = \"/global/cfs/cdirs/m3443/usr/pmtuan/HadronicMCData/train_data_2_particles_processed/\"\n",
    "data_files = os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'n_particle': 1,\n",
    "    'max_etot': 100000,\n",
    "    'min_etot': 10000,\n",
    "    'gen_hidden_activation': 'LeakyReLU',\n",
    "    'dis_hidden_activation': 'LeakyReLU',\n",
    "    'gen_output_activation': 'LeakyReLU',\n",
    "    'dis_output_activation': 'Sigmoid',\n",
    "    'gen_batchnorm': True,\n",
    "    'dis_batchnorm': True,\n",
    "    'gen_dropout_rate': 0.5,\n",
    "    'dis_dropout_rate': 0.,\n",
    "    'nb_gen_layer': 10,\n",
    "    'nb_dis_layer': 10,\n",
    "    'gen_lr': 0.001,\n",
    "    'dis_lr': 0.001,\n",
    "    \n",
    "    'sort_by': 0,\n",
    "    'batch_size': 1024,\n",
    "    'input_dir': '/global/cfs/cdirs/m3443/usr/pmtuan/HadronicMCData/2_particle_fstate',\n",
    "    'hidden':  128,\n",
    "    \n",
    "    'noise_dim': 4,\n",
    "    'cond_dim': 1,\n",
    "    'gen_in': 4,\n",
    "    'gen_dim': 4,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p12, m12, outcome = read_data(os.path.join(DATA_PATH, data_files[0]))\n",
    "outcome = sort_particle(outcome, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import logging\n",
    "\n",
    "class MCDataModule(LightningDataModule):\n",
    "    def __init__(self, hparams) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.trainset, self.valset, self.testset = None, None, None\n",
    "    \n",
    "    def convert_dataset(self, dataset):\n",
    "        return torch.utils.data.TensorDataset(* dataset )\n",
    "\n",
    "    def setup(self, stage='fit'):\n",
    "\n",
    "        logging.info('Reading data')\n",
    "\n",
    "        datasets = {\n",
    "            name: os.path.join(self.hparams['input_dir'], name) for name in ['train', 'val', 'test']\n",
    "        }\n",
    "\n",
    "        if stage=='fit':\n",
    "\n",
    "            self.trainset, self.valset = [\n",
    "                [torch.tensor(ds) for ds in read_data([ os.path.join(datasets[name], f) for f in  os.listdir(datasets[name])], max_etot=self.hparams.get('max_etot'), prog_bar=True)   ]\n",
    "                for name in ['train', 'val']\n",
    "            ]\n",
    "            self.trainset, self.valset = self.transform(self.trainset), self.transform(self.valset)\n",
    "        \n",
    "        if stage=='test':\n",
    "            self.testset = [torch.tensor(ds) for ds in read_data([ os.path.join(datasets['test'], f) for f in  os.listdir(datasets['test'])], max_etot=self.hparams.get('max_etot'), prog_bar=True) ]\n",
    "            self.testset = self.transform(self.testset)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.convert_dataset(self.trainset), \n",
    "            batch_size=self.hparams['batch_size'])\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.convert_dataset(self.valset), \n",
    "            batch_size=self.hparams['batch_size'])\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.convert_dataset(self.testset), \n",
    "            batch_size=self.hparams['batch_size'])\n",
    "    \n",
    "    def transform(self, dataset):\n",
    "        etot, m, outcome = dataset\n",
    "        outcome = outcome[:, : self.hparams['n_particle'] ].reshape((outcome.shape[0], -1))\n",
    "        outcome /= etot\n",
    "        etot /= 1000.\n",
    "        m /= 1000.\n",
    "        return [etot, m, outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:40<00:00,  1.67it/s]\n",
      "100%|██████████| 33/33 [00:21<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data_module = CartesianDataModule(hparams)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[20.0000],\n",
      "        [70.0000],\n",
      "        [50.0000],\n",
      "        ...,\n",
      "        [50.0000],\n",
      "        [20.0000],\n",
      "        [60.0000]], dtype=torch.float64), tensor([[1.0778],\n",
      "        [1.0778],\n",
      "        [1.0779],\n",
      "        ...,\n",
      "        [1.0778],\n",
      "        [1.0779],\n",
      "        [1.0778]], dtype=torch.float64), tensor([[ 5.0108e-01, -8.4955e-03,  5.0653e-03, -4.9878e-01],\n",
      "        [ 5.0009e-01, -1.6370e-04,  2.3869e-03, -4.9990e-01],\n",
      "        [ 5.0017e-01,  8.6553e-04, -2.2275e-03, -4.9981e-01],\n",
      "        ...,\n",
      "        [ 5.0017e-01, -3.1510e-03, -1.7474e-03, -4.9981e-01],\n",
      "        [ 5.0108e-01, -1.7072e-02,  2.4805e-03, -4.9858e-01],\n",
      "        [ 5.0012e-01, -1.5018e-03,  4.1806e-03, -4.9986e-01]],\n",
      "       dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for i in data_module.train_dataloader():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('hadsim_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e83746e3048c1e7681ea3da4fb484a227c1ffd1dae52935990ec24d7b2045666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
